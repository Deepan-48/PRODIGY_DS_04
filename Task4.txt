# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from sklearn.feature_extraction.text import CountVectorizer
from wordcloud import WordCloud
import zipfile # import zipfile to extract the csv

# Download stopwords if not already downloaded
nltk.download('stopwords')
nltk.download('punkt')

# Load the dataset
from google.colab import files
uploaded = files.upload()

# Extract the csv file from the uploaded zip file
with zipfile.ZipFile('twitter_training.csv.zip', 'r') as zip_ref:
    zip_ref.extractall('.')

# Now read the extracted csv file
data = pd.read_csv('twitter_training.csv', header=None) # Add header=None

# Display the first few rows of the dataset
print(data.head())

# Assign column names
data.columns = ['Tweet ID', 'Entity', 'Sentiment', 'Text'] # Assuming the first row contains headers

# ... (rest of the code remains the same)
plt.figure(figsize=(8,6))
sns.countplot(x='Sentiment', data=data) # Change 'sentiment' to 'Sentiment'
plt.title('Sentiment Distribution')
plt.show()

# Word cloud for positive sentiment
positive_text = ' '.join(data[data['Sentiment'] == 'positive']['clean_text']) # Change 'sentiment' to 'Sentiment'
wordcloud_positive = WordCloud(width=800, height=400, background_color='white').generate(positive_text)

plt.figure(figsize=(10,5))
plt.imshow(wordcloud_positive, interpolation='bilinear')
plt.title('Word Cloud for Positive Sentiment')
plt.axis('off')
plt.show()

# Word cloud for negative sentiment
negative_text = ' '.join(data[data['Sentiment'] == 'negative']['clean_text']) # Change 'sentiment' to 'Sentiment'
wordcloud_negative = WordCloud(width=800, height=400, background_color='black').generate(negative_text)

plt.figure(figsize=(10,5))
plt.imshow(wordcloud_negative, interpolation='bilinear')
plt.title('Word Cloud for Negative Sentiment')
plt.axis('off')
plt.show()

# Sentiment analysis based on time (if timestamp is available)
# Convert timestamp to datetime format and extract date
if 'timestamp' in data.columns:
    data['date'] = pd.to_datetime(data['timestamp']).dt.date

    # Group by date and sentiment
    sentiment_by_date = data.groupby(['date', 'Sentiment']).size().unstack().fillna(0) # Change 'sentiment' to 'Sentiment'

    # Plot sentiment trends over time
    plt.figure(figsize=(12,6))
    sentiment_by_date.plot()
    plt.title('Sentiment Trends Over Time')
    plt.xlabel('Date')
    plt.ylabel('Count')
    plt.show()
else:
    print("Timestamp column not available in the dataset for time-based analysis.")

# Preprocess the data
def preprocess_text(text):
    # Convert text to lowercase
    text = text.lower()
    # Tokenize text
    words = word_tokenize(text)
    # Remove stopwords and non-alphabetic characters
    words = [word for word in words if word.isalpha() and word not in stopwords.words('english')]
    return ' '.join(words)

data['clean_text'] = data['Text'].apply(preprocess_text) # Apply preprocess_text to the 'Text' column

# Display the first few rows after preprocessing
print(data[['Text', 'clean_text']].head()) # Change 'text' to 'Text'